---
title: CPU 矩阵乘法前人优化路径探案：从 perf 数据到 AVX-512 真相
summary: 如何用系统化的方式理解产品设计中的对话与反馈循环。
pubDate: 2025-10-06
# tags:
#   - 产品设计
#   - 用户体验
---

import { Image } from 'astro:assets'
import hero from '../../assets/posts/Basic_MMM.png'

> 知其然到知其所以然

<Image
  src={hero}
  alt="示意图"
  widths={[480, 768, 1200]}
  sizes="(min-width: 768px) 768px, 100vw"
  class="rounded-xl border border-slate-200 shadow-sm dark:border-slate-700 dark:bg-slate-900/60"
/>
<div class="caption">基本矩阵乘法</div>
# 引言
在高性能计算领域，通用矩阵乘法（GEMM）的优化是一个永恒的议题。它看似简单的三层循环背后，蕴藏着对现代CPU体系结构理解的深度考验，从缓存层次、内存带宽到指令级并行，每一处都可能是性能的瓶颈所在。对于追求极致性能的开发者而言，深入探索GEMM的优化不仅是一项技术挑战，更是一次通往计算机系统底层的旅行。

幸运的是，前行之路上已有灯塔指引。近年来，有很多杰出的技术博客和论文为我们绘制了详尽的优化地图，它们从不同的视角出发，引领我们一步步将一个朴素的实现推向性能极限。在开始自己的探索之前，有必要向部分卓越的工作致以敬意，并梳理它们的贡献。

| 文章出处 & 链接                                                                                                                                        | 关键贡献与Insights                                                                                                                       |
| -------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [**Fast MMM on CPU**](https://siboehm.com/articles/22/Fast-MMM-on-CPU) by S. Boehm                                           | <li>通过清晰的、可复现的步骤，展示了每次优化（如循环重排、Tiling）带来的直观性能增益。</li><li>强调了理论与实践的结合，每一步优化都有坚实的性能数据作为支撑。</li><li>为初学者和中级实践者提供了一条友好的学习路径。</li> |
| [**CPU Matrix Multiplication from Scratch**](https://blog.pebblesandweeds.com/cpu_matmul_blog.html) by V. Rejichev                | <li>系统性地将向量化（SIMD）分解为五大要素：指令集、数据对齐、预取、转置和循环展开。</li><li>提供了具体的AVX2 intrinsic代码示例，深入探讨了SIMD编程的实践细节。</li><li>其核心价值在于对SIMD这一关键优化技术的“解构式”教学。</li> |
| [**Advanced Matrix Multiplication Optimization**](https://salykova.github.io/gemm-cpu) by A. Salykova              | <li>引入并实践了BLIS（BLAS-like Library Instantiation Software）框架的设计哲学。</li><li>阐述了“微内核”（micro-kernel）在最大化寄存器复用中的核心作用。</li><li>展示了针对多级缓存的阻塞（Blocking）策略和内存打包（Packing）的必要性，提供了一个可扩展的高性能架构。</li> |

站在这些巨人的肩膀上，任何试图在该领域撰写新文章的尝试都显得野心勃勃。上述文章已经从算法、架构和工程实践等多个维度，对GEMM优化进行了精妙的阐述。作为一个仍在学习路上的探索者，我无意也无力提出一种全新的、超越前人的优化算法。

然而，在学习和复现这些工作的过程中，我发现了一个可以补充的视角。这些文章卓越地回答了“**做什么（What）**”和“**为什么（Why）**”——我们应该做什么样的优化，以及为什么这些优化在理论上是有效的。但对于实践者而言，一个更为根本的问题或许是：“**如何确证（How to Verify）**”。当我们的代码并未如预期般加速时，我们如何通过量化数据，**诊断出性能瓶颈究竟是缓存未命中、并行度低，还是别的什么原因？**

因此，本文的目的并非提出一种新的优化技术，而是试图进行一次**探索**。使用 `perf`、`Compiler Explorer` 等工具，对GEMM的优化过程进行分析。

我们将从最朴素的实现出发，在每一步之后，将分析性能剖析工具给出的“证据”——例如缓存未命中率的变化、CPU指令周期的消耗、以及编译器生成的汇编代码的差异等，然后应用前人的优化对比效果。此外，我们将把目光投向更为现代的AVX-512指令集，探究其为微内核设计带来的新机遇与挑战。

本文希望为那些不仅想知道“怎么做”，更想知道“如何观察和验证”的读者，提供一套可操作的诊断思路。让我们开始这次探案之旅。

---
我将在不同的机器配置下进行测试

配置一：
- CPU: Intel Core i7-11800H（8 核 16 线程，Tiger Lake 架构）
- RAM: 32GB DDR4 3200MHz CL22
- OS: Ubuntu 22.04 LTS
- Compiler: g++ 11.4.0 
- Perf: 5.15.189

配置二：
- CPU: AMD Ryzen 9950X（16 核 32 线程，ZEN 5 架构）
- RAM: 64GB DDR5 6000 MHz CL30
- OS: Ubuntu 22.04 LTS
- Compiler: g++ 11.4.0 
### 第一幕：性能杀手——Cache Miss
我们将聚焦于Naive实现的矩阵乘法，并使用工具收集初步的性能数据。

从一个基本的嵌套 for 循环开始

#### **代码：`gemm_naive.cpp`**

实现采用 `(i, j, k)` 的循环顺序，直接对应数学公式 `C[i][j] = Σ A[i][k] * B[k][j]` 。所有矩阵均以一维向量形式存储，遵循行主序（Row-Major Order）内存布局，用于计算两个N x N的单精度浮点矩阵`A`和`B`的乘积，结果存入`C`。

```cpp
// Function to perform naive matrix multiplication
// C = A * B
// Loops order: i, j, k
void gemm_naive(const std::vector<float>& A, const std::vector<float>& B, std::vector<float>& C, int N) {
    for (int i = 0; i < N; ++i) {
        for (int j = 0; j < N; ++j) {
            float sum = 0.0f;
            for (int k = 0; k < N; ++k) {
                // C(i, j) is the dot product of row i of A and column j of B
                sum += A[i * N + k] * B[k * N + j];
            }
            C[i * N + j] = sum;
        }
    }
}
```

我们将使用 `perf` 工具集，它是Linux内核自带的性能分析工具，能够访问处理器的性能监控单元（PMU），从而提供底层的硬件事件计数。你需要准备好Linux环境下的`g++`编译器和`perf`工具。

将上面的代码保存为文件 `gemm_naive.cpp`。然后打开终端，使用以下命令进行编译：

```bash
g++ -O3 -o gemm_naive gemm_naive.cpp
```

首先，让我们直接运行程序，看看它的性能表现。
```bash
./gemm_naive
```

你将会看到类似下面的输出：

```
Matrix Size: 256x256          Matrix Size: 512x512           Matrix Size: 1024x1024
Elapsed Time: 0.0150155 s     Elapsed Time: 0.131208 s       Elapsed Time: 2.30336 s
Performance: 2.23465 GFLOPS   Performance: 2.04588 GFLOPS    Performance: 0.932325 GFLOPS
```
<div class="caption">配置一性能表现</div>

现在，到了最关键的一步。我们将使用`perf`工具，像X光机一样透视程序在CPU上运行时的内部情况。我们将重点关注与缓存和CPU周期相关的硬件事件。

在终端中运行以下命令：

```bash
perf stat -e L1-dcache-load-misses,cache-misses,cycles,instructions ./gemm_naive
```

*   **`perf stat`**: `perf`工具的统计模式。
*   **`-e`**: 用于指定我们感兴趣的硬件事件（events）。
*   **`L1-dcache-load-misses`**: **核心证据**。CPU尝试从最快的一级数据缓存（L1d cache）中读取数据但失败的次数。这个比例越高，说明缓存命中率越低。
*   **`cache-misses`**: 所有级别缓存（L1, L2, L3）的总未命中率。这是一个宏观指标。
*   **`cycles`, `instructions`**: CPU执行的总时钟周期数和总指令数。这两个值可以用来计算**CPI（Cycles Per Instruction）**，即执行平均一条指令需要多少个时钟周期。

我们对朴素GEMM实现在三种不同输入规模（N=256, 512, 1024）下进行了测试，并利用`perf`工具收集了关键的硬件性能计数器。测试平台CPU为Intel Core i7-11800H，其拥有24MB的L3缓存（Intel® Smart Cache）。

**数据汇总表:**

| 矩阵尺寸 (N) | 工作集大小 | GFLOPS | IPC | L1 D-Cache Misses | LLC Misses |
| :------------- | :--------------- | :----- | :---------------- | :------------------ | :---------------------------- |
| 256            | 512 KB           | 2.32   | 1.85              | 17.5 M            | 17.4 K                        |
| 512            | 2 MB             | 2.05   | 1.67              | 135.8 M           | 82.8 K                        |
| 1024           | 8 MB             | 0.99   | 0.84              | 1.07 B            | 1.52 M                        |

**分析:**

**阶段一：缓存延迟被有效隐藏 (N=256 & N=512)**

在N=256和N=512的规模下，程序的计算数据足迹（512KB和2MB）远小于CPU的24MB L3缓存。

*   **性能剖面**: 程序的IPC（每周期指令数）分别为1.85和1.67，表现出较高的指令执行效率，表明CPU流水线在此阶段相对流畅。
*   **缓存行为**:
    *   在N=512时，程序执行了约 **2.68亿次** 内存加载操作。
    *   最后一级缓存（LLC）的未命中次数为 **82,845次**。
    *   由此计算得出，**LLC的未命中率仅为 0.031%** (`82,845 / 2.68e8`)。
*   **结论**: 尽管L1缓存未命中率很高，但只有极少数（约万分之三）的内存请求最终需要从主内存（DRAM）中获取。绝大多数请求都在高速的L2/L3缓存中得到满足。**正是因为这个极低的LLC未命中率**，CPU的乱序执行能力能够有效隐藏大部分内存访问延迟，从而维持了较高的IPC。

**阶段二：内存瓶颈显现 (N=1024)**

当矩阵尺寸增加到N=1024时，性能剖面发生了质变。

*   **性能剖面**: GFLOPS骤降至不足1.0，IPC从1.67**暴跌至0.84**，CPU开始出现严重的执行停顿。
*   **缓存行为**:
    *   在N=1024时，总加载操作次数增至约 **21.4亿次**。
    *   LLC的未命中次数**激增至152万次**。
    *   计算得出的 **LLC未命中率上升至0.071%** (`1.52e6 / 21.4e9`)。
*   **结论**: LLC未命中率的百分比从0.031%增长到0.071%，其**绝对数量**增长了近20倍。而每一次LLC未命中都意味着一次对极慢的主存的访问。当这种高成本事件的发生次数从8.3万次增到152万次时，其累积的延迟时间 (`总停顿时间 ≈ 152万 * 数百周期`) 变得巨大。CPU的绝大多数时间都在等待数据，导致IPC下跌。程序从计算受限转变为**内存访问受限（Memory-Bound）**。

**总结:**
本次基准测试能一定程度反映**朴素GEMM算法的内在缺陷——糟糕的内存访问模式——是其性能低下的根本原因**。当问题规模较小，数据可完全容纳于高速缓存时，这一缺陷被硬件能力部分掩盖；一旦问题规模增大并触及缓存容量的临界点，性能便会断崖式下跌。这为我们后续的优化指明了唯一的方向：改善数据局部性，从根本上降低缓存未命中率。

